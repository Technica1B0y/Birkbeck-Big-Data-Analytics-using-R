\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={CW1\_13154855\_A\_Guo},
            pdfauthor={Anyi Guo},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{CW1\_13154855\_A\_Guo}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Anyi Guo}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{16/10/2018}


\begin{document}
\maketitle

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Statistical learning methods
\end{enumerate}

For each of parts (a) through (d), indicate whether we would generally
expect the performance of a flexible statistical learning method to be
better or worse than an inflexible method. Justify your answer.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  The sample size n is extremely large, and the number of predictors p
  is small.\\
  Flexible method would work better. This is because the large sample
  size means that it's less likely for us to overfit the data. Flexible
  methods also tends to reduce bias.
\item
  The number of predictors p is extremely large, and the number of
  observations n is small.
\end{enumerate}

Inflexible method would work better. A flexible method is likely to
cause overfitting in this instance.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  The relationship between the predictors and response is highly
  non-linear.
\end{enumerate}

A flexible model would work better. This is because we need to use its
flexibility to fit the non-linear nature of the data.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  The variance of the error terms, i.e.~σ2 = Var(ε), is extremely
  high.\\
  An inflexible model would work better. This is because a flexible
  model would easily overfit the model and conveys too much noise due to
  the large variance in errors.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Descriptive analysis
\end{enumerate}

In a higher educational institution the comprehensive applied
mathematics exam is comprised of two parts. On the first day, 20
students took the exam, the results of which are presented below:

Oral exam results: 4, 1, 4, 5, 3, 2, 3, 4, 3, 5, 2, 2, 4, 3, 5, 5, 1, 1,
1, 2.\\
Written exam results: 2,3,1,4,2,5,3,1,2,1,2,2,1,1,2,3,1,2,3,4.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Use R to calculate the mean, the mode, the median, the variance and
  the standard deviation of the oral and written exams separately and
  together as well.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oral<-}\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{written<-}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\NormalTok{combined <-}\KeywordTok{c}\NormalTok{(oral,written)}

\NormalTok{findmode <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(i) \{}
\NormalTok{   uniqi <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(i)}
\NormalTok{   uniqi[}\KeywordTok{which.max}\NormalTok{(}\KeywordTok{tabulate}\NormalTok{(}\KeywordTok{match}\NormalTok{(i, uniqi)))]}
\NormalTok{\}}

\NormalTok{exam <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DataTypeTok{nrow=}\DecValTok{3}\NormalTok{,}\DataTypeTok{ncol=}\DecValTok{5}\NormalTok{)}
\KeywordTok{colnames}\NormalTok{(exam)=}\KeywordTok{c}\NormalTok{(}\StringTok{"Mean"}\NormalTok{,}\StringTok{"Mode"}\NormalTok{,}\StringTok{"Median"}\NormalTok{,}\StringTok{"Variance"}\NormalTok{,}\StringTok{"Std Deviation"}\NormalTok{)}
\KeywordTok{rownames}\NormalTok{(exam)=}\KeywordTok{c}\NormalTok{(}\StringTok{"Oral"}\NormalTok{,}\StringTok{"Written"}\NormalTok{,}\StringTok{"Combined"}\NormalTok{)}
\NormalTok{exam[}\DecValTok{1}\NormalTok{,]<-}\KeywordTok{c}\NormalTok{(}\KeywordTok{mean}\NormalTok{(oral),}\KeywordTok{findmode}\NormalTok{(oral),}\KeywordTok{median}\NormalTok{(oral),}\KeywordTok{var}\NormalTok{(oral),}\KeywordTok{sd}\NormalTok{(oral))}
\NormalTok{exam[}\DecValTok{2}\NormalTok{,]<-}\KeywordTok{c}\NormalTok{(}\KeywordTok{mean}\NormalTok{(written),}\KeywordTok{findmode}\NormalTok{(written),}\KeywordTok{median}\NormalTok{(written),}\KeywordTok{var}\NormalTok{(written),}\KeywordTok{sd}\NormalTok{(written))}
\NormalTok{exam[}\DecValTok{3}\NormalTok{,]<-}\KeywordTok{c}\NormalTok{(}\KeywordTok{mean}\NormalTok{(combined),}\KeywordTok{findmode}\NormalTok{(combined),}\KeywordTok{median}\NormalTok{(combined),}\KeywordTok{var}\NormalTok{(combined),}\KeywordTok{sd}\NormalTok{(combined))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Find the covariance and correlation between the oral and written exam
  scores.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{cov}\NormalTok{(oral,written))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.3157895
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{cor}\NormalTok{(oral,written))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.1869531
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Is there a positive or negative or no correlation between the two?
\end{enumerate}

There is a slightly negative correlation between the two.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Is there causation between the two? Justify your answers.
\end{enumerate}

Not sure. Correlation does not necessarily signify causation - we'll
need more data to substantiate that claim.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Descriptive analysis This exercise involves the Auto data set studied
  in the class. Make sure that the missing values have been removed from
  the data.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Which of the predictors are quantitative, and which are qualitative?
\end{enumerate}

Quantitative: \texttt{mpg}, \texttt{cylinders},\texttt{displacement},
\texttt{horsepower}, \texttt{weight},
\texttt{acceleration},\texttt{year} Qualitative: \texttt{origin},
\texttt{name}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ISLR)}
\NormalTok{Auto<-}\KeywordTok{na.omit}\NormalTok{(Auto)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  What is the range of each quantitative predictor? You can answer this
  using the range() function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Get range for each column}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)\{}
        \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The range for"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(Auto)[i], }\StringTok{"is"}\NormalTok{, }\KeywordTok{range}\NormalTok{(Auto[,i])[}\DecValTok{1}\NormalTok{],}\StringTok{"~"}\NormalTok{,}\KeywordTok{range}\NormalTok{(Auto[,i])[}\DecValTok{2}\NormalTok{]))}
\NormalTok{        \}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The range for mpg is 9 ~ 46.6"
## [1] "The range for cylinders is 3 ~ 8"
## [1] "The range for displacement is 68 ~ 455"
## [1] "The range for horsepower is 46 ~ 230"
## [1] "The range for weight is 1613 ~ 5140"
## [1] "The range for acceleration is 8 ~ 24.8"
## [1] "The range for year is 70 ~ 82"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  What is the mean and standard deviation of each quantitative
  predictor?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get Mean for each column}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)\{}
        \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The mean for"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(Auto)[i], }\StringTok{"is"}\NormalTok{, }\KeywordTok{mean}\NormalTok{(Auto[,i])))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The mean for mpg is 23.4459183673469"
## [1] "The mean for cylinders is 5.4719387755102"
## [1] "The mean for displacement is 194.411989795918"
## [1] "The mean for horsepower is 104.469387755102"
## [1] "The mean for weight is 2977.58418367347"
## [1] "The mean for acceleration is 15.5413265306122"
## [1] "The mean for year is 75.9795918367347"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# get Standard Deviation for each column}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)\{}
        \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The standard deviation for"}\NormalTok{,}\KeywordTok{colnames}\NormalTok{(Auto)[i],}\StringTok{"is"}\NormalTok{,}\KeywordTok{sd}\NormalTok{(Auto[,i])))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The standard deviation for mpg is 7.8050074865718"
## [1] "The standard deviation for cylinders is 1.70578324745278"
## [1] "The standard deviation for displacement is 104.644003908905"
## [1] "The standard deviation for horsepower is 38.4911599328285"
## [1] "The standard deviation for weight is 849.402560042949"
## [1] "The standard deviation for acceleration is 2.75886411918808"
## [1] "The standard deviation for year is 3.68373654357783"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Now remove the 10th through 85th observations. What is the range,
  mean, and standard deviation of each predictor in the subset of the
  data that remains?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newAuto<-Auto[}\OperatorTok{-}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{85}\NormalTok{)]}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{)\{}
        \KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"In the subset newAuto, the range for"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(newAuto)[i], }\StringTok{"is"}\NormalTok{, }\KeywordTok{range}\NormalTok{(newAuto[,i])[}\DecValTok{1}\NormalTok{],}\StringTok{"~"}\NormalTok{,}\KeywordTok{range}\NormalTok{(newAuto[,i])[}\DecValTok{2}\NormalTok{],}\StringTok{", the mean is"}\NormalTok{,}\KeywordTok{mean}\NormalTok{(newAuto[,i]), }\StringTok{", the standard deviation is"}\NormalTok{,}\KeywordTok{sd}\NormalTok{(newAuto[,i])))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "In the subset newAuto, the range for mpg is 9 ~ 46.6 , the mean is 23.4459183673469 , the standard deviation is 7.8050074865718"
## [1] "In the subset newAuto, the range for cylinders is 3 ~ 8 , the mean is 5.4719387755102 , the standard deviation is 1.70578324745278"
## [1] "In the subset newAuto, the range for displacement is 68 ~ 455 , the mean is 194.411989795918 , the standard deviation is 104.644003908905"
## [1] "In the subset newAuto, the range for horsepower is 46 ~ 230 , the mean is 104.469387755102 , the standard deviation is 38.4911599328285"
## [1] "In the subset newAuto, the range for weight is 1613 ~ 5140 , the mean is 2977.58418367347 , the standard deviation is 849.402560042949"
## [1] "In the subset newAuto, the range for acceleration is 8 ~ 24.8 , the mean is 15.5413265306122 , the standard deviation is 2.75886411918808"
## [1] "In the subset newAuto, the range for year is 70 ~ 82 , the mean is 75.9795918367347 , the standard deviation is 3.68373654357783"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Using the full data set, investigate the predictors graphically, using
  scatterplots or other tools of your choice. Create some plots
  highlighting the relationships among the predictors. Comment on your
  findings.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{cylinders) }
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the higher the mpg, the lower the number of cylinders. Number of cylinders is not continuous. }

\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{displacement) }\CommentTok{# there seems to be a negative polynomial correlation between mpg and displacement}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-7-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{horsepower) }\CommentTok{# this chart seems to indicate a negative linear/polynomial correlation between mpg and horsepower}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-7-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{weight) }\CommentTok{# seems to be a negative linear(?)correlation between mpg and weight}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-7-4.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{acceleration) }\CommentTok{# this chart seems to indicate a positive linear/polynomial relationship between mpg and acceleration}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-7-5.pdf}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Suppose that we wish to predict gas mileage (mpg) on the basis of the
  other variables. Do your plots suggest that any of the other variables
  might be useful in predicting mpg? Justify your answer. In addition to
  the 5 quantitative columns, the \texttt{Origin} and \texttt{Year}
  column may also be useful in predicting mpg.
\end{enumerate}

\texttt{Origin}: the higher the number
(i.e.~Japanese\textgreater{}European\textgreater{}America), the higher
the mpg tends to be.

\texttt{Year}: the later the year, the higher the mpg tends to be.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{origin)}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-8-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{mpg,Auto}\OperatorTok{$}\NormalTok{year)}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-8-2.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Linear regression This question involves the use of simple linear
  regression on the Auto data set.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Use the lm() function to perform a simple linear regression with mpg
  as the response and horsepower as the predictor. Use the summary()
  function to print the results. Comment on the output. For example:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit<-}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{horsepower,}\DataTypeTok{data=}\NormalTok{Auto)}
\KeywordTok{summary}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ horsepower, data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.5710  -3.2592  -0.3435   2.7630  16.9240 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 39.935861   0.717499   55.66   <2e-16 ***
## horsepower  -0.157845   0.006446  -24.49   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.906 on 390 degrees of freedom
## Multiple R-squared:  0.6059, Adjusted R-squared:  0.6049 
## F-statistic: 599.7 on 1 and 390 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  Is there a relationship between the predictor and the response?\\
  Yes.
\item
  How strong is the relationship between the predictor and the
  response?\\
  The relationship is strong (i.e.~above significance level)
\item
  Is the relationship between the predictor and the response positive or
  negative?\\
  Negative.
\item
  What is the predicted mpg associated with a horsepower of 98? What are
  the associated 95\% confidence and prediction intervals?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Confidence interval is"}\NormalTok{,}\KeywordTok{predict}\NormalTok{(lm.fit,}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{horsepower=}\DecValTok{98}\NormalTok{),}\DataTypeTok{interval=}\StringTok{"confidence"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Confidence interval is 24.4670771525124"
## [2] "Confidence interval is 23.9730789607039"
## [3] "Confidence interval is 24.9610753443209"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Prediction is"}\NormalTok{,}\KeywordTok{predict}\NormalTok{(lm.fit,}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{horsepower=}\DecValTok{98}\NormalTok{),}\DataTypeTok{interval=}\StringTok{"prediction"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Prediction is 24.4670771525124" "Prediction is 14.8093960709667"
## [3] "Prediction is 34.1247582340581"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Plot the response and the predictor. Use the abline() function to
  display the least squares regression line.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit<-}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{horsepower,}\DataTypeTok{data=}\NormalTok{Auto)}
\NormalTok{nd <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{horsepower=}\KeywordTok{seq}\NormalTok{(}\DecValTok{46}\NormalTok{,}\DecValTok{230}\NormalTok{))}
\NormalTok{p_conf <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(lm.fit,}\DataTypeTok{interval=}\StringTok{"confidence"}\NormalTok{,}\DataTypeTok{newdata=}\NormalTok{nd)}
\NormalTok{p_pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(lm.fit,}\DataTypeTok{interval=}\StringTok{"prediction"}\NormalTok{,}\DataTypeTok{newdata=}\NormalTok{nd)}

\KeywordTok{plot}\NormalTok{(Auto}\OperatorTok{$}\NormalTok{horsepower,Auto}\OperatorTok{$}\NormalTok{mpg)}
\KeywordTok{abline}\NormalTok{(lm.fit)}

\KeywordTok{lines}\NormalTok{(nd}\OperatorTok{$}\NormalTok{horse, p_conf[,}\StringTok{"lwr"}\NormalTok{], }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\StringTok{"+"}\NormalTok{) }
\KeywordTok{lines}\NormalTok{(nd}\OperatorTok{$}\NormalTok{horse, p_conf[,}\StringTok{"upr"}\NormalTok{], }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\StringTok{"+"}\NormalTok{) }
\KeywordTok{lines}\NormalTok{(nd}\OperatorTok{$}\NormalTok{horse, p_pred[,}\StringTok{"upr"}\NormalTok{], }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\StringTok{"*"}\NormalTok{) }
\KeywordTok{lines}\NormalTok{(nd}\OperatorTok{$}\NormalTok{horse, p_pred[,}\StringTok{"lwr"}\NormalTok{], }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"b"}\NormalTok{, }\DataTypeTok{pch=}\StringTok{"*"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Plot the 95\% confidence interval and prediction interval in the same
  plot as (b) using different colours and legends.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Logistic regression Using the Boston data set, fit classification
  models in order to predict whether a given suburb has a crime rate
  above or below the median. Explore logistic regression models using
  various subsets of the predictors. Describe your findings. Using
  \texttt{crim} as the response, there are 13 variables in the Boston
  dataset which can be used as predictors. We'll devide them into 3 sets
  and run logistic regrssion on them.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(MASS)}
\NormalTok{b<-Boston}
\CommentTok{#b$chas=factor(b$chas)}
\NormalTok{b}\OperatorTok{$}\NormalTok{aboveMean<-}\KeywordTok{ifelse}\NormalTok{(b}\OperatorTok{$}\NormalTok{crim}\OperatorTok{>=}\KeywordTok{median}\NormalTok{(b}\OperatorTok{$}\NormalTok{crim),}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}

\NormalTok{glm1.fit<-}\KeywordTok{glm}\NormalTok{(aboveMean}\OperatorTok{~}\NormalTok{zn}\OperatorTok{+}\NormalTok{indus}\OperatorTok{+}\NormalTok{chas}\OperatorTok{+}\NormalTok{nox,}\DataTypeTok{data=}\NormalTok{b,}\DataTypeTok{family=}\NormalTok{binomial)}
\NormalTok{glm2.fit<-}\KeywordTok{glm}\NormalTok{(aboveMean}\OperatorTok{~}\NormalTok{rm}\OperatorTok{+}\NormalTok{age}\OperatorTok{+}\NormalTok{dis}\OperatorTok{+}\NormalTok{rad,}\DataTypeTok{data=}\NormalTok{b,}\DataTypeTok{family=}\NormalTok{binomial)}
\NormalTok{glm3.fit<-}\KeywordTok{glm}\NormalTok{(aboveMean}\OperatorTok{~}\NormalTok{tax}\OperatorTok{+}\NormalTok{ptratio}\OperatorTok{+}\NormalTok{black}\OperatorTok{+}\NormalTok{lstat}\OperatorTok{+}\NormalTok{medv,}\DataTypeTok{data=}\NormalTok{b,}\DataTypeTok{family=}\NormalTok{binomial)}
\KeywordTok{summary}\NormalTok{(glm1.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = aboveMean ~ zn + indus + chas + nox, family = binomial, 
##     data = b)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.08994  -0.35257  -0.00903   0.38042   2.90846  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -17.51038    2.10203  -8.330  < 2e-16 ***
## zn           -0.04415    0.02357  -1.873   0.0610 .  
## indus        -0.08060    0.03315  -2.431   0.0150 *  
## chas          0.98879    0.56457   1.751   0.0799 .  
## nox          34.19738    4.33510   7.888 3.06e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 701.46  on 505  degrees of freedom
## Residual deviance: 306.71  on 501  degrees of freedom
## AIC: 316.71
## 
## Number of Fisher Scoring iterations: 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(glm2.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = aboveMean ~ rm + age + dis + rad, family = binomial, 
##     data = b)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.78845  -0.49284  -0.02264   0.02224   2.79655  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -3.631969   1.649565  -2.202   0.0277 *  
## rm           0.047502   0.208176   0.228   0.8195    
## age          0.032776   0.007439   4.406 1.05e-05 ***
## dis         -0.468341   0.107832  -4.343 1.40e-05 ***
## rad          0.463656   0.094360   4.914 8.94e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 701.46  on 505  degrees of freedom
## Residual deviance: 317.22  on 501  degrees of freedom
## AIC: 327.22
## 
## Number of Fisher Scoring iterations: 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(glm3.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = aboveMean ~ tax + ptratio + black + lstat + medv, 
##     family = binomial, data = b)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.3298  -0.6746  -0.1547   0.4507   2.1967  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -2.641916   2.538653  -1.041  0.29803    
## tax          0.009009   0.001163   7.749 9.28e-15 ***
## ptratio      0.090524   0.064766   1.398  0.16220    
## black       -0.018465   0.005774  -3.198  0.00139 ** 
## lstat        0.166843   0.029933   5.574 2.49e-08 ***
## medv         0.109197   0.022252   4.907 9.24e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 701.46  on 505  degrees of freedom
## Residual deviance: 418.79  on 500  degrees of freedom
## AIC: 430.79
## 
## Number of Fisher Scoring iterations: 7
\end{verbatim}

\textbf{Conclusion} The following columns have minimum impact on the
response, i.e.~they are not useful predictors, so it is fine to leave
them out of the model: \texttt{rm} \texttt{ptratio} \texttt{chas} (only
.) \texttt{zn} (only .)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Resampling methods
\end{enumerate}

Suppose that we use some statistical learning method to make a
prediction for the response Y for a particular value of the predictor X.
Carefully describe how we might estimate the standard deviation of our
prediction.

There are three different ways

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Resampling methods We will now perform cross-validation on a simulated
  data set.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Generate a simulated data set as follows:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{x =}\StringTok{ }\DecValTok{4} \OperatorTok{-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\NormalTok{x }\OperatorTok{-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{2} \OperatorTok{+}\StringTok{ }\DecValTok{3}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{4} \OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In this data set, what is n and what is p? Write out the model used to
generate the data in equation form.

In this data set, n is 500 and p is x. The model used is stated above -
\texttt{y\ =\ x\ -\ 2*x\^{}2\ +\ 3*x\^{}4\ +\ rnorm(500)}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Create a scatterplot of X against Y. Comment on what you find.
\end{enumerate}

There seems to be a positive non-linear relationship between x and y.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(x,y)}
\end{Highlighting}
\end{Shaded}

\includegraphics{CW1_13154855_A_GUO_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Set the seed to be 23, and then compute the LOOCV and 10-fold CV
  errors that result from fitting the following four models using least
  squares:
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Y = β0 + β1X + ε
\item
  Y =β0 +β1X+β2X2 +ε
\item
  Y =β0 +β1X+β2X2 +β3X3 +ε
\item
  Y =β0 +β1X+β2X2 +β3X3 +β4X4 +ε.
\end{enumerate}

Note you may find it helpful to use the data.frame() function to create
a single data set containing both X and Y.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(boot)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{23}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{x =}\StringTok{ }\DecValTok{4} \OperatorTok{-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\NormalTok{x }\OperatorTok{-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{2} \OperatorTok{+}\StringTok{ }\DecValTok{3}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{4} \OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{df<-}\KeywordTok{data.frame}\NormalTok{(x,y)}

\CommentTok{# first model Y = β0 + β1X + ε}
\NormalTok{glm.fit <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x,}\DataTypeTok{data=}\NormalTok{df)}
\NormalTok{cv.err <-}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(df,glm.fit)}
\NormalTok{cv.err}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 195337.3 195332.9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.err2<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit,}\DataTypeTok{K=}\DecValTok{10}\NormalTok{)}
\NormalTok{cv.err2}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 193314.7 193191.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The LOOCV error for first model is"}\NormalTok{,cv.err}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{],}\StringTok{" and the 10-fold CV error for the first model is"}\NormalTok{,cv.err2}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The LOOCV error for first model is 195337.297150242  and the 10-fold CV error for the first model is 193314.650140994"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# second model Y =β0 +β1X+β2X^2 +ε}
\NormalTok{glm.fit2<-}\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x}\OperatorTok{+}\KeywordTok{poly}\NormalTok{(x,}\DecValTok{2}\NormalTok{),}\DataTypeTok{data=}\NormalTok{df)}
\NormalTok{cv.err<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit2)}
\NormalTok{cv.err}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11865.41 11864.35
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.err2<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit2,}\DataTypeTok{K=}\DecValTok{10}\NormalTok{)}
\NormalTok{cv.err2}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12018.45 11954.68
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The LOOCV error for second model is"}\NormalTok{,cv.err}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{],}\StringTok{" and the 10-fold CV error for the second model is"}\NormalTok{,cv.err2}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The LOOCV error for second model is 11865.4098083307  and the 10-fold CV error for the second model is 12018.4546211804"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# third model Y =β0 +β1X+β2X2 +β3X3 +ε}
\NormalTok{glm.fit3<-}\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x}\OperatorTok{+}\KeywordTok{poly}\NormalTok{(x,}\DecValTok{3}\NormalTok{),}\DataTypeTok{data=}\NormalTok{df)}
\NormalTok{cv.err<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit3)}
\NormalTok{cv.err}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 151.4818 151.4412
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.err2<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit3,}\DataTypeTok{K=}\DecValTok{10}\NormalTok{)}
\NormalTok{cv.err2}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 157.8909 155.3729
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The LOOCV error for the third model is"}\NormalTok{,cv.err}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{],}\StringTok{" and the 10-fold CV error for the third model is"}\NormalTok{,cv.err2}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The LOOCV error for the third model is 151.481840745374  and the 10-fold CV error for the third model is 157.89093422738"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# fourth model Y =β0 +β1X+β2X2 +β3X3 +β4X4 +ε. }
\NormalTok{glm.fit4<-}\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x}\OperatorTok{+}\KeywordTok{poly}\NormalTok{(x,}\DecValTok{4}\NormalTok{),}\DataTypeTok{data=}\NormalTok{df)}
\NormalTok{cv.err<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit4)}
\NormalTok{cv.err}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.046784 1.046738
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.err2<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit4,}\DataTypeTok{K=}\DecValTok{10}\NormalTok{)}
\NormalTok{cv.err2}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.059236 1.056028
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Repeat (c) using random seed 46, and report your results. Are your
  results the same as what you got in (c)? Why?
\end{enumerate}

The results are not the same as when using \texttt{set.seed(23)}. This
is because \texttt{set.seed()} generates a random set of numbers.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{46}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{x =}\StringTok{ }\DecValTok{4} \OperatorTok{-}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\NormalTok{x }\OperatorTok{-}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{2} \OperatorTok{+}\StringTok{ }\DecValTok{3}\OperatorTok{*}\NormalTok{x}\OperatorTok{^}\DecValTok{4} \OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}
\NormalTok{df<-}\KeywordTok{data.frame}\NormalTok{(x,y)}

\CommentTok{# first model Y = β0 + β1X + ε}
\NormalTok{glm.fit <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x,}\DataTypeTok{data=}\NormalTok{df)}
\NormalTok{cv.err <-}\StringTok{ }\KeywordTok{cv.glm}\NormalTok{(df,glm.fit)}
\NormalTok{cv.err}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 212789.7 212785.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv.err2<-}\KeywordTok{cv.glm}\NormalTok{(df,glm.fit,}\DataTypeTok{K=}\DecValTok{10}\NormalTok{)}
\NormalTok{cv.err2}\OperatorTok{$}\NormalTok{delta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 212191.2 211980.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"The LOOCV error for first model is"}\NormalTok{,cv.err}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{],}\StringTok{" and the 10-fold CV error for the first model is"}\NormalTok{,cv.err2}\OperatorTok{$}\NormalTok{delta[}\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "The LOOCV error for first model is 212789.740894727  and the 10-fold CV error for the first model is 212191.155996556"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Which of the models in (c) had the smallest LOOCV and 10-fold CV
  error? Is this what you expected? Explain your answer.
\end{enumerate}

The fourth model has the smallest LOOCV and 10-fold CV error. This is
what I expected

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Comment on the statistical significance of the coefficient estimates
  that results from fitting each of the models in (c) using least
  squares. Do these results agree with the conclusions drawn based on
  the cross-validation results?
\end{enumerate}


\end{document}
